---
layout: post
title: EIA data and R
author: Petr Baca
published: false
status: process
draft: false
tags: R
---
##### EIA data and R

Amount of data available via web services has been soaring in the recent years. One of the organisations that decided to make its data publicly available via web is the [Energy Information Administration](http://www.eia.gov) (EIA). The EIA is in fact something as a statistical arm of the US Department of Energy and its task is, among other things, to created widely and closely followed analyses such as the Short Term Energy Outlook([STEO](http://www.eia.gov/forecasts/steo/report/)). For that reason, the EIA also collects huge amount of energy-related data. And this data is now available via the API.

##### EIA API? Just great!

[API](http://en.wikipedia.org/wiki/Application_programming_interface), or Application Programming Interface maintained by the EIA is great! Although it still is "just" a beta-version and as such suffers from some childhood diseases (for example, there are some inconsistencies in naming simillar time series), it is very useful source of information. After a (free) registration, the user can reques a unique user key to be able to download [XML](https://en.wikipedia.org/wiki/XML) files directly from the web via [REST](http://en.wikipedia.org/wiki/Representational_state_transfer)ful services.

What does it mean and how does it work? From user's viewpoint, RESTful services are in fact quite simple. All one needs to do is to send a 'database query' in a form of a particular 'web address'. That is, it reminds simply writing 'www.google.com' into web browsers window. As a response, the server returns an XML file that contains requested data.

After getting the data, all the user needs to do is to extract the information he or she is looking for. To show an example, we will use [R](http://www.r-project.org/). The reason is simple. After getting the data the user usually wants to perform some sort of analysis and R is a great tool for such goal.

##### EIA & R = <3

R certainly is one of the best tools for data analysis that is easily available. One of the reasons is that it supports [web technologies](http://cran.r-project.org/web/views/WebTechnologies.html). So, equipped with this kind of information, how should one proceed?

First, We will have to download some external libraries from the list above. Namely, we need __RCurl__ and __XML__ libraries. To be able to work with time series data more efficiently we will also get __xts__ library.

So, let's say we want to download monthly data on the US crude oil production. Anyone who has ever heard of "the shale revolution" would know that this kind of data has been attracting a lot of attention in the recent years.

After a while one can easily find [this](http://www.eia.gov/opendata/qb.cfm?category=296686&sdid=PET.MCRFPUS2.M) webpage. It contains all the information we need to know, in particular the code of the series (__PET.MCRFPUS2.M__). If we have the code, we can retrieve and process the data using the following script (warning: you have to use your own API key to be able to use the script).

```{r true_url, echo = FALSE}
URL <- "http://api.eia.gov/series/?api_key=A3C0FAC177DFBC4B1A4C157DC8198257&series_id=PET.MCRFPUS2.M&out=xml"
```

First, we will activate the libraries.

```{r load_packages, message=FALSE}
library("RCurl") # data retrieval
library("XML") # XML parsing
library("xts") # to be able to convert to a 'nice' time series object

```

The following chunk shows how to actually get and process the data.

```{r eia_data}
# we will keep the URL (or URI) in variable URL
# don't forget to get your own API key

#URL <- "http://api.eia.gov/series/?api_key=YOUR_API_KEY_HERE&series_id=PET.MCRFPUS2.M&out=xml"

# data download and processing
XML <- getURL(URL, httpheader = list('User-Agent' = 'R-Agent'))
tree <- xmlTreeParse(XML, useInternalNodes=TRUE)
  
# get values of interest from the XML file
date <- xpathSApply(tree,"//series/row/data/row/date", xmlValue)
value <- xpathSApply(tree,"//series/row/data/row/value", function(x) as.numeric(xmlValue(x)))

# OK, now let's convert the data to time series object
# first, convert date so that R understands it really is date
d <- as.Date(paste(substr(date, 1, 4),
                   substr(date, 5, 6),
                   "01", sep = "-"))

# save the results to variable called 'prod'
prod <- xts(value, d); colnames(prod) <- "US_oil_prod"

# ...and show the data for the last 12 months (available)
tail(prod, 12)

```

Now, we can easily plot the data we just downloaded...

```{r plot, echo=TRUE}
plot(prod, main = "Monthly US crude oil production", ylab = "thousand barrels per day")
```

You may be thinking. Why should I do it? Why should I learn how to write an R script when I could simply download the same data in an excel file or see the plot on EIA website?

Well, there are many reasons! The most important one probably is that the script above (or the report based on the script such as this blog post) is reproducible. That means that you can run exactly the same script next month, get a coffee (or rather take a look from the window for 5 seconds) and the new plot is done!

Of course, you can do much more than just simple plot the data. One obvious extension of the script above for example is to wrap its key parts into a function that can download the data for any time series. And as far as the comparison of analytical tools available in R and in Excel is concerned, needles to say that the former goes far beyond what can you do in Excel spreadsheet...

